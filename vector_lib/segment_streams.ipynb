{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "from shapely.ops import split, unary_union\n",
    "from shapely.geometry.polygon import orient\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from skimage.morphology import skeletonize\n",
    "from geoprocessing_tools import multipolygon_to_polygon\n",
    "\n",
    "def create_centerline(polygon_file, output_CL_file, tolerance=50):\n",
    "    \"\"\"Process each polygon in the GeoPackage to create centerlines, apply smoothing, and save them.\"\"\"\n",
    "\n",
    "    def polygon_to_raster(poly, cell_size=1):\n",
    "        \"\"\"Convert a polygon to a raster array.\"\"\"\n",
    "        bounds = poly.bounds\n",
    "        width = int(np.ceil((bounds[2] - bounds[0]) / cell_size))\n",
    "        height = int(np.ceil((bounds[3] - bounds[1]) / cell_size))\n",
    "        transform = rasterio.transform.from_origin(bounds[0], bounds[3], cell_size, cell_size)\n",
    "        raster = rasterize([(poly, 1)], out_shape=(height, width), transform=transform)\n",
    "        return raster, transform\n",
    "\n",
    "    def raster_to_centerline(raster, transform):\n",
    "        \"\"\"Convert raster array to a centerline geometry.\"\"\"\n",
    "        skeleton = skeletonize(raster == 1)\n",
    "        points = [Point(*rasterio.transform.xy(transform, row, col, offset='center'))\n",
    "                  for row in range(skeleton.shape[0]) for col in range(skeleton.shape[1]) if skeleton[row, col]]\n",
    "        if points:\n",
    "            line = LineString(points)\n",
    "            return line\n",
    "        return None\n",
    "\n",
    "    def smooth_line(line, tolerance):\n",
    "        \"\"\"Smooth the line geometry using the Douglas-Peucker algorithm.\"\"\"\n",
    "        if line:\n",
    "            return line.simplify(tolerance, preserve_topology=False)\n",
    "        return line\n",
    "\n",
    "    def calc_centerline(polygon, cell_size=1):\n",
    "        \"\"\"Main function to create and smooth centerline from a polygon.\"\"\"\n",
    "        raster, transform = polygon_to_raster(polygon, cell_size)\n",
    "        centerline = raster_to_centerline(raster, transform)\n",
    "        smoothed_centerline = smooth_line(centerline, tolerance)\n",
    "        return smoothed_centerline\n",
    "\n",
    "    gdf = gpd.read_file(polygon_file)\n",
    "    gdf['centerline'] = gdf['geometry'].apply(lambda x: calc_centerline(x))\n",
    "\n",
    "    # Remove entries where no centerline was found\n",
    "    centerlines_gdf = gdf.dropna(subset=['centerline'])\n",
    "    centerlines_gdf = centerlines_gdf.set_geometry('centerline', drop=True)  # Set 'centerline' as the geometry column and drop the old one\n",
    "    centerlines_gdf.crs = gdf.crs  # Ensure CRS is preserved\n",
    "    # Save to a new GeoPackage\n",
    "    centerlines_gdf.to_file(output_CL_file, driver='GPKG')\n",
    "\n",
    "    return centerlines_gdf\n",
    "\n",
    "\n",
    "def create_perpendicular_lines(gpkg_path, distance=100, spacing=1):\n",
    "    # Load the centerline from the geopackage\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    \n",
    "    # Initialize an empty list to store perpendicular lines\n",
    "    perpendiculars = []\n",
    "    \n",
    "    # Iterate through each feature in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "        geometry = row['geometry']\n",
    "        \n",
    "        # Handle MultiLineString appropriately using `geoms`\n",
    "        if isinstance(geometry, MultiLineString):\n",
    "            line_parts = geometry.geoms\n",
    "        else:\n",
    "            line_parts = [geometry]\n",
    "\n",
    "        # Process each line part\n",
    "        for line in line_parts:\n",
    "            coords = np.array(line.coords)\n",
    "            for i in range(0, len(coords) - 1, spacing):  # Adjust spacing here\n",
    "                p1, p2 = coords[i], coords[i+1]\n",
    "                dx, dy = p2[0] - p1[0], p2[1] - p1[1]\n",
    "                \n",
    "                # Calculate the perpendicular vector\n",
    "                len_vector = np.sqrt(dx**2 + dy**2)\n",
    "                perp_vector = (-dy, dx)\n",
    "                \n",
    "                # Normalize and scale the vector\n",
    "                perp_vector = (perp_vector[0] / len_vector * distance, perp_vector[1] / len_vector * distance)\n",
    "                \n",
    "                # Calculate mid-point of the line segment\n",
    "                mid_point = ((p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2)\n",
    "                \n",
    "                # Create the perpendicular line segment\n",
    "                perp_line = LineString([\n",
    "                    (mid_point[0] + perp_vector[0], mid_point[1] + perp_vector[1]),\n",
    "                    (mid_point[0] - perp_vector[0], mid_point[1] - perp_vector[1])\n",
    "                ])\n",
    "                \n",
    "                # Append the perpendicular line to the list\n",
    "                perpendiculars.append({'geometry': perp_line})\n",
    "    \n",
    "    # Convert list to GeoDataFrame\n",
    "    perpendiculars_gdf = gpd.GeoDataFrame(perpendiculars, crs=gdf.crs)\n",
    "    \n",
    "    # Save the perpendicular lines to the same geopackage\n",
    "    out_gpkg_path = gpkg_path.replace('.gpkg', '_perpendiculars.gpkg')\n",
    "    perpendiculars_gdf.to_file(out_gpkg_path, driver='GPKG')\n",
    "\n",
    "def create_smooth_perpendicular_lines(gpkg_path, line_length=60, spacing=5, window=20):\n",
    "    # Load the centerline from the geopackage\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    \n",
    "    # Initialize an empty list to store perpendicular lines\n",
    "    perpendiculars = []\n",
    "    \n",
    "    # Iterate through each feature in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "        geometry = row['geometry']\n",
    "        \n",
    "        # Handle MultiLineString appropriately using `geoms`\n",
    "        if isinstance(geometry, MultiLineString):\n",
    "            line_parts = geometry.geoms\n",
    "        else:\n",
    "            line_parts = [geometry]\n",
    "\n",
    "        # Process each line part\n",
    "        for line in line_parts:\n",
    "            length = line.length\n",
    "            num_samples = int(np.floor(length / spacing))\n",
    "            for i in range(num_samples + 1):\n",
    "                # Calculate the point at each meter\n",
    "                point = line.interpolate(i * spacing)\n",
    "                \n",
    "                # Get points 20 meters ahead and behind\n",
    "                point_back = line.interpolate(max(0, i * spacing - window))\n",
    "                point_forward = line.interpolate(min(length, i * spacing + window))\n",
    "                \n",
    "                # Calculate vectors to these points\n",
    "                dx_back, dy_back = point.x - point_back.x, point.y - point_back.y\n",
    "                dx_forward, dy_forward = point_forward.x - point.x, point_forward.y - point.y\n",
    "                \n",
    "                # Average the vectors\n",
    "                dx_avg = (dx_back + dx_forward) / 2\n",
    "                dy_avg = (dy_back + dy_forward) / 2\n",
    "                \n",
    "                # Calculate the perpendicular vector\n",
    "                len_vector = np.sqrt(dx_avg**2 + dy_avg**2)\n",
    "                perp_vector = (-dy_avg, dx_avg)\n",
    "                \n",
    "                # Normalize and scale the vector\n",
    "                perp_vector = (perp_vector[0] / len_vector * line_length, perp_vector[1] / len_vector * line_length)\n",
    "                \n",
    "                # Create the perpendicular line segment\n",
    "                perp_line = LineString([\n",
    "                    (point.x + perp_vector[0], point.y + perp_vector[1]),\n",
    "                    (point.x - perp_vector[0], point.y - perp_vector[1])\n",
    "                ])\n",
    "                \n",
    "                # Append the perpendicular line to the list\n",
    "                perpendiculars.append({'geometry': perp_line})\n",
    "    \n",
    "    # Convert list to GeoDataFrame\n",
    "    perpendiculars_gdf = gpd.GeoDataFrame(perpendiculars, crs=gdf.crs)\n",
    "    \n",
    "    # Save the perpendicular lines to the same geopackage\n",
    "    out_gpkg_path = gpkg_path.replace('.gpkg', '_perpendiculars_100m.gpkg')\n",
    "    perpendiculars_gdf.to_file(out_gpkg_path, driver='GPKG')\n",
    "\n",
    "def segment_stream_polygon(stream_polygon_path, centerline_path, output_path, n_segments = 200, window=20):\n",
    "    # Load the shapefile and the centerline\n",
    "    gdf = gpd.read_file(stream_polygon_path)\n",
    "    centerline_gdf = gpd.read_file(centerline_path)\n",
    "    \n",
    "    # Assuming the polygon to segment is the first feature in the shapefile\n",
    "    polygon = gdf.geometry[0]\n",
    "    centerline = centerline_gdf.geometry[0]\n",
    "    \n",
    "    # Calculate interval along the centerline to place cutting points\n",
    "    line_length = centerline.length\n",
    "    interval = line_length / n_segments\n",
    "    \n",
    "    # Initialize list to store cutting lines\n",
    "    cutting_lines = []\n",
    "    \n",
    "    for i in range(1, n_segments):\n",
    "        # Calculate the primary interpolation point\n",
    "        point = centerline.interpolate(i * interval)\n",
    "\n",
    "        # Calculate points 20 meters behind and ahead for rolling average\n",
    "        point_back = centerline.interpolate(max(0, i * interval - window))\n",
    "        point_forward = centerline.interpolate(min(line_length, i * interval + window))\n",
    "        \n",
    "        # Determine vectors to these points\n",
    "        dx_back, dy_back = point.x - point_back.x, point.y - point_back.y\n",
    "        dx_forward, dy_forward = point_forward.x - point.x, point_forward.y - point.y\n",
    "        \n",
    "        # Average the vectors\n",
    "        dx_avg = (dx_back + dx_forward) / 2\n",
    "        dy_avg = (dy_back + dy_forward) / 2\n",
    "        \n",
    "        # Compute the perpendicular vector\n",
    "        length_vector = np.sqrt(dx_avg**2 + dy_avg**2)\n",
    "        perp_dx = -dy_avg / length_vector\n",
    "        perp_dy = dx_avg / length_vector\n",
    "        \n",
    "        # Define a long perpendicular line for cutting\n",
    "        start_point = Point(point.x + perp_dx * 1000, point.y + perp_dy * 1000)\n",
    "        end_point = Point(point.x - perp_dx * 1000, point.y - perp_dy * 1000)\n",
    "        cutting_lines.append(LineString([start_point, end_point]))\n",
    "    \n",
    "    # Initial set of segments\n",
    "    segments = [polygon]\n",
    "\n",
    "    # Split the polygon with each line\n",
    "    for line in cutting_lines:\n",
    "        new_segments = []\n",
    "        for segment in segments:\n",
    "            split_result = split(segment, line)\n",
    "            new_segments.extend(split_result.geoms)\n",
    "        segments = new_segments\n",
    "\n",
    "    # Convert segments to GeoDataFrame\n",
    "    segment_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries(segments))\n",
    "\n",
    "    # Set the same CRS as the original\n",
    "    segment_gdf.crs = gdf.crs\n",
    "\n",
    "    # Save to a new shapefile\n",
    "    segment_gdf.to_file(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def rank_elevation_mean(input_geopackage, output_geopackage):\n",
    "    \"\"\"\n",
    "    Reads a GeoPackage, ranks features based on the 'Elevation Mean' field,\n",
    "    adds these ranks as a new field 'id', and writes the result to a new GeoPackage.\n",
    "\n",
    "    Parameters:\n",
    "    input_geopackage (str): Path to the input GeoPackage.\n",
    "    output_geopackage (str): Path to the output GeoPackage where the result will be saved.\n",
    "    \"\"\"\n",
    "    # Load the geopackage into a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_geopackage)\n",
    "\n",
    "    # Check if 'Elevation Mean' column exists\n",
    "    if 'Elevation Mean' not in gdf.columns:\n",
    "        raise ValueError(\"The column 'Elevation Mean' does not exist in the provided GeoPackage.\")\n",
    "\n",
    "    # Rank the 'Elevation Mean' values from smallest to largest\n",
    "    # Method should be one of 'average', 'min', 'max', 'first', 'dense'\n",
    "    gdf['fid'] = gdf['Elevation Mean'].rank(method='first').astype(int)\n",
    "\n",
    "    # Write the modified GeoDataFrame to a new geopackage\n",
    "    gdf.to_file(output_geopackage, driver='GPKG')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_hillslope_attributes import aggregate_raster_stats\n",
    "import os\n",
    "\n",
    "channel_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Channel Polygons JTM\"\n",
    "centerline_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Centerlines\"\n",
    "output_single_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\One Part Polygons\"\n",
    "output_segment_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Segmented Polygons\"\n",
    "\n",
    "\n",
    "#channel_poly_paths = [os.path.join(channel_poly_dir, f) for f in os.listdir(channel_poly_dir) if f.endswith('.gpkg')]\n",
    "#centerline_paths = [os.path.join(centerline_dir, f) for f in os.listdir(centerline_dir) if f.endswith('.gpkg')]\n",
    "\n",
    "channel_poly_paths = [\n",
    "    r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\ME_Channel.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\MM_Channel.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\MW_Channel.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\UE_Channel.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\UM_Channel.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\UW_Channel.gpkg\",\n",
    "]\n",
    "\n",
    "centerline_paths = [\n",
    "    r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\ME_centerline.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\MM_centerline.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\MW_centerline.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\UE_centerline.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\UM_centerline.gpkg\",\n",
    "r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\UW_centerline.gpkg\",\n",
    "]\n",
    "\n",
    "output_rough_CL_dir = r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\"\n",
    "\n",
    "if not os.path.exists(output_single_poly_dir):\n",
    "    os.makedirs(output_single_poly_dir)\n",
    "if not os.path.exists(output_segment_poly_dir):\n",
    "    os.makedirs(output_segment_poly_dir)\n",
    "if not os.path.exists(output_rough_CL_dir):\n",
    "    os.makedirs(output_rough_CL_dir)\n",
    "\n",
    "DEM_path = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Terrain Feature Rasters\\Slope.tif\"\n",
    "#\n",
    "segmented_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Segmented Polygons\"\n",
    "segmented_poly_paths = [os.path.join(segmented_poly_dir, f) for f in os.listdir(segmented_poly_dir) if f.endswith('.gpkg')]\n",
    "\n",
    "for channel_path, centerline_path in zip(channel_poly_paths, centerline_paths):\n",
    "    single_poly_name = os.path.basename(channel_path)[0:3] + \"_channel_single_poly.gpkg\"\n",
    "    output_single_poly_path = os.path.join(output_single_poly_dir, single_poly_name)\n",
    "    # output_segment_name = os.path.basename(channel_path)[0:3] + \"_channel_segmented.gpkg\"\n",
    "    # output_segment_poly_path = os.path.join(output_segment_poly_dir, output_segment_name)\n",
    "    output_CL_file = os.path.join(output_rough_CL_dir, \"Rough \" + os.path.basename(centerline_path))\n",
    "    \n",
    "    multipolygon_to_polygon(channel_path, output_single_poly_path)\n",
    "    create_centerline(output_single_poly_path, output_CL_file, tolerance=300)\n",
    "\n",
    "    #segment_stream_polygon(output_single_poly_path, centerline_path, output_segment_poly_path)\n",
    "# for output_segment_poly_path in segmented_poly_paths:\n",
    "#     stats_fields = { 'mean': 'Slope Mean'}\n",
    "#     gdf = gpd.read_file(output_segment_poly_path)\n",
    "#     aggregate_raster_stats(DEM_path, gdf, output_shapefile_path=output_segment_poly_path, **stats_fields)\n",
    "    #rank_elevation_mean(output_segment_poly_path, output_segment_poly_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The generated centerline falls outside the polygon.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Polygon, Point\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def get_centroid_elevation(centroid, dem):\n",
    "    \"\"\"\n",
    "    Gets the elevation of a centroid by sampling the DEM.\n",
    "    \n",
    "    Parameters:\n",
    "    centroid (shapely.geometry.Point): The centroid to get the elevation for.\n",
    "    dem (rasterio.io.DatasetReader): The DEM raster data.\n",
    "    \n",
    "    Returns:\n",
    "    elevation (float): The elevation at the centroid location.\n",
    "    \"\"\"\n",
    "    coords = [(centroid.x, centroid.y)]\n",
    "    for val in dem.sample(coords):\n",
    "        return val[0]\n",
    "\n",
    "def order_centroids_by_elevation(centroids, dem):\n",
    "    \"\"\"\n",
    "    Orders centroids by elevation.\n",
    "    \n",
    "    Parameters:\n",
    "    centroids (GeoDataFrame): The centroids to order.\n",
    "    dem (rasterio.io.DatasetReader): The DEM raster data.\n",
    "    \n",
    "    Returns:\n",
    "    ordered_centroids (GeoDataFrame): The centroids ordered by elevation.\n",
    "    \"\"\"\n",
    "    # Get elevations for all centroids\n",
    "    centroids['elevation'] = centroids.geometry.apply(lambda centroid: get_centroid_elevation(centroid, dem))\n",
    "    \n",
    "    # Sort by elevation in ascending order\n",
    "    centroids = centroids.sort_values(by=['elevation'])\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "def create_centerline_from_skeleton(polygon, dem_path, buffer_size=10):\n",
    "    \"\"\"\n",
    "    Creates a centerline from an irregular polygon representing a river channel\n",
    "    using skeletonization. Connects adjacent centroids starting from the lowest\n",
    "    elevation and going up to the highest.\n",
    "    \n",
    "    Parameters:\n",
    "    polygon (shapely.geometry.Polygon): The input river channel polygon.\n",
    "    dem_path (str): The file path to the DEM raster data.\n",
    "    buffer_size (float): The buffer size used to find adjacent centroids.\n",
    "\n",
    "    Returns:\n",
    "    centerline (shapely.geometry.LineString): The generated centerline.\n",
    "    centroids_gdf (geopandas.GeoDataFrame): The centroids as a GeoDataFrame for troubleshooting.\n",
    "    \"\"\"\n",
    "    # Ensure the polygon is valid\n",
    "    polygon = polygon.buffer(0)\n",
    "\n",
    "    # Load the DEM\n",
    "    dem = rasterio.open(dem_path)\n",
    "\n",
    "    # Convert polygon to a binary image\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    width = int(np.ceil(maxx - minx))\n",
    "    height = int(np.ceil(maxy - miny))\n",
    "    \n",
    "    # Create a grid of points within the polygon's bounding box\n",
    "    x = np.linspace(minx, maxx, width)\n",
    "    y = np.linspace(miny, maxy, height)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Create an image mask where points inside the polygon are 1, outside are 0\n",
    "    mask = np.array([polygon.contains(Point(x[i, j], y[i, j])) for i in range(height) for j in range(width)])\n",
    "    mask = mask.reshape((height, width))\n",
    "    \n",
    "    # Skeletonize the binary mask\n",
    "    skeleton = skeletonize(mask)\n",
    "\n",
    "    # Find the contours of the skeleton and create centroids\n",
    "    contours = measure.find_contours(skeleton, 0.5)\n",
    "    centroids = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        # Convert pixel coordinates back to original coordinates\n",
    "        points = [(x[int(coord[0]), int(coord[1])], y[int(coord[0]), int(coord[1])]) for coord in contour]\n",
    "        \n",
    "        # Create a Polygon from the contour points (assuming triangles)\n",
    "        if len(points) >= 3:\n",
    "            triangle = Polygon(points)\n",
    "            if triangle.is_valid and triangle.area > 0:\n",
    "                centroid = triangle.centroid\n",
    "                if polygon.contains(centroid):\n",
    "                    centroids.append({'fid': idx, 'geometry': centroid})\n",
    "    \n",
    "    # Convert centroids to GeoDataFrame\n",
    "    centroids_gdf = gpd.GeoDataFrame(centroids, crs=\"EPSG:6342\")\n",
    "\n",
    "    # Order centroids by elevation\n",
    "    ordered_centroids_gdf = order_centroids_by_elevation(centroids_gdf, dem)\n",
    "\n",
    "    # Create a LineString that connects the ordered centroids\n",
    "    if len(ordered_centroids_gdf) > 1:\n",
    "        centerline = LineString(ordered_centroids_gdf.geometry.tolist())\n",
    "        # Ensure the centerline is fully within the original polygon\n",
    "        if not polygon.contains(centerline):\n",
    "            print(\"Warning: The generated centerline falls outside the polygon.\")\n",
    "           # centerline = None\n",
    "    else:\n",
    "        centerline = None  # Handle cases where no valid centerline could be generated\n",
    "\n",
    "    return centerline, ordered_centroids_gdf\n",
    "\n",
    "# Load your river channel polygon and DEM from a GeoPackage or other source\n",
    "gdf = gpd.read_file(r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\ME_Channel.gpkg\")\n",
    "dem_path = r\"Y:\\ATD\\GIS\\Bennett\\DEMs LIDAR\\2013 DEM OT ndv.tif\"\n",
    "\n",
    "# Assuming there's only one polygon, or iterate through a list if there are multiple\n",
    "polygon = gdf.geometry.iloc[0]\n",
    "centerline, centroids_gdf = create_centerline_from_skeleton(polygon, dem_path, buffer_size=1)\n",
    "\n",
    "# Save the centerline to a new layer in the GeoPackage\n",
    "if centerline:\n",
    "    centerline_gdf = gpd.GeoDataFrame(geometry=[centerline], crs=gdf.crs)\n",
    "    centerline_gdf.to_file(r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\test_centerline.gpkg\", driver=\"GPKG\")\n",
    "    print(\"Centerline generated successfully.\")\n",
    "else:\n",
    "    print(\"No valid centerline could be generated.\")\n",
    "\n",
    "# Save the centroids to a new layer in the GeoPackage\n",
    "centroids_gdf.to_file(r\"Y:\\ATD\\GIS\\Bennett\\Channel Polygons\\Centerlines\\test_centroids.gpkg\", driver=\"GPKG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Point\n",
    "from shapely.ops import split, unary_union\n",
    "from shapely.geometry.polygon import orient\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from skimage.morphology import skeletonize\n",
    "from geoprocessing_tools import multipolygon_to_polygon\n",
    "\n",
    "def create_centerline(polygon_file, output_CL_file, tolerance=50):\n",
    "    \"\"\"Process each polygon in the GeoPackage to create centerlines, apply smoothing, and save them.\"\"\"\n",
    "\n",
    "    def polygon_to_raster(poly, cell_size=1):\n",
    "        \"\"\"Convert a polygon to a raster array.\"\"\"\n",
    "        bounds = poly.bounds\n",
    "        width = int(np.ceil((bounds[2] - bounds[0]) / cell_size))\n",
    "        height = int(np.ceil((bounds[3] - bounds[1]) / cell_size))\n",
    "        transform = rasterio.transform.from_origin(bounds[0], bounds[3], cell_size, cell_size)\n",
    "        raster = rasterize([(poly, 1)], out_shape=(height, width), transform=transform)\n",
    "        return raster, transform\n",
    "\n",
    "    def raster_to_centerline(raster, transform):\n",
    "        \"\"\"Convert raster array to a centerline geometry.\"\"\"\n",
    "        skeleton = skeletonize(raster == 1)\n",
    "        points = [Point(*rasterio.transform.xy(transform, row, col, offset='center'))\n",
    "                  for row in range(skeleton.shape[0]) for col in range(skeleton.shape[1]) if skeleton[row, col]]\n",
    "        if points:\n",
    "            line = LineString(points)\n",
    "            return line\n",
    "        return None\n",
    "\n",
    "    def smooth_line(line, tolerance):\n",
    "        \"\"\"Smooth the line geometry using the Douglas-Peucker algorithm.\"\"\"\n",
    "        if line:\n",
    "            return line.simplify(tolerance, preserve_topology=False)\n",
    "        return line\n",
    "\n",
    "    def calc_centerline(polygon, cell_size=1):\n",
    "        \"\"\"Main function to create and smooth centerline from a polygon.\"\"\"\n",
    "        raster, transform = polygon_to_raster(polygon, cell_size)\n",
    "        centerline = raster_to_centerline(raster, transform)\n",
    "        smoothed_centerline = smooth_line(centerline, tolerance)\n",
    "        return smoothed_centerline\n",
    "\n",
    "    gdf = gpd.read_file(polygon_file)\n",
    "    gdf['centerline'] = gdf['geometry'].apply(lambda x: calc_centerline(x))\n",
    "\n",
    "    # Remove entries where no centerline was found\n",
    "    centerlines_gdf = gdf.dropna(subset=['centerline'])\n",
    "    centerlines_gdf = centerlines_gdf.set_geometry('centerline', drop=True)  # Set 'centerline' as the geometry column and drop the old one\n",
    "    centerlines_gdf.crs = gdf.crs  # Ensure CRS is preserved\n",
    "    # Save to a new GeoPackage\n",
    "    centerlines_gdf.to_file(output_CL_file, driver='GPKG')\n",
    "\n",
    "    return centerlines_gdf\n",
    "\n",
    "\n",
    "def create_perpendicular_lines(gpkg_path, distance=100, spacing=1):\n",
    "    # Load the centerline from the geopackage\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    \n",
    "    # Initialize an empty list to store perpendicular lines\n",
    "    perpendiculars = []\n",
    "    \n",
    "    # Iterate through each feature in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "        geometry = row['geometry']\n",
    "        \n",
    "        # Handle MultiLineString appropriately using `geoms`\n",
    "        if isinstance(geometry, MultiLineString):\n",
    "            line_parts = geometry.geoms\n",
    "        else:\n",
    "            line_parts = [geometry]\n",
    "\n",
    "        # Process each line part\n",
    "        for line in line_parts:\n",
    "            coords = np.array(line.coords)\n",
    "            for i in range(0, len(coords) - 1, spacing):  # Adjust spacing here\n",
    "                p1, p2 = coords[i], coords[i+1]\n",
    "                dx, dy = p2[0] - p1[0], p2[1] - p1[1]\n",
    "                \n",
    "                # Calculate the perpendicular vector\n",
    "                len_vector = np.sqrt(dx**2 + dy**2)\n",
    "                perp_vector = (-dy, dx)\n",
    "                \n",
    "                # Normalize and scale the vector\n",
    "                perp_vector = (perp_vector[0] / len_vector * distance, perp_vector[1] / len_vector * distance)\n",
    "                \n",
    "                # Calculate mid-point of the line segment\n",
    "                mid_point = ((p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2)\n",
    "                \n",
    "                # Create the perpendicular line segment\n",
    "                perp_line = LineString([\n",
    "                    (mid_point[0] + perp_vector[0], mid_point[1] + perp_vector[1]),\n",
    "                    (mid_point[0] - perp_vector[0], mid_point[1] - perp_vector[1])\n",
    "                ])\n",
    "                \n",
    "                # Append the perpendicular line to the list\n",
    "                perpendiculars.append({'geometry': perp_line})\n",
    "    \n",
    "    # Convert list to GeoDataFrame\n",
    "    perpendiculars_gdf = gpd.GeoDataFrame(perpendiculars, crs=gdf.crs)\n",
    "    \n",
    "    # Save the perpendicular lines to the same geopackage\n",
    "    out_gpkg_path = gpkg_path.replace('.gpkg', '_perpendiculars.gpkg')\n",
    "    perpendiculars_gdf.to_file(out_gpkg_path, driver='GPKG')\n",
    "\n",
    "def create_smooth_perpendicular_lines(gpkg_path, line_length=60, spacing=5, window=20):\n",
    "    # Load the centerline from the geopackage\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    \n",
    "    # Initialize an empty list to store perpendicular lines\n",
    "    perpendiculars = []\n",
    "    \n",
    "    # Iterate through each feature in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "        geometry = row['geometry']\n",
    "        \n",
    "        # Handle MultiLineString appropriately using `geoms`\n",
    "        if isinstance(geometry, MultiLineString):\n",
    "            line_parts = geometry.geoms\n",
    "        else:\n",
    "            line_parts = [geometry]\n",
    "\n",
    "        # Process each line part\n",
    "        for line in line_parts:\n",
    "            length = line.length\n",
    "            num_samples = int(np.floor(length / spacing))\n",
    "            for i in range(num_samples + 1):\n",
    "                # Calculate the point at each meter\n",
    "                point = line.interpolate(i * spacing)\n",
    "                \n",
    "                # Get points 20 meters ahead and behind\n",
    "                point_back = line.interpolate(max(0, i * spacing - window))\n",
    "                point_forward = line.interpolate(min(length, i * spacing + window))\n",
    "                \n",
    "                # Calculate vectors to these points\n",
    "                dx_back, dy_back = point.x - point_back.x, point.y - point_back.y\n",
    "                dx_forward, dy_forward = point_forward.x - point.x, point_forward.y - point.y\n",
    "                \n",
    "                # Average the vectors\n",
    "                dx_avg = (dx_back + dx_forward) / 2\n",
    "                dy_avg = (dy_back + dy_forward) / 2\n",
    "                \n",
    "                # Calculate the perpendicular vector\n",
    "                len_vector = np.sqrt(dx_avg**2 + dy_avg**2)\n",
    "                perp_vector = (-dy_avg, dx_avg)\n",
    "                \n",
    "                # Normalize and scale the vector\n",
    "                perp_vector = (perp_vector[0] / len_vector * line_length, perp_vector[1] / len_vector * line_length)\n",
    "                \n",
    "                # Create the perpendicular line segment\n",
    "                perp_line = LineString([\n",
    "                    (point.x + perp_vector[0], point.y + perp_vector[1]),\n",
    "                    (point.x - perp_vector[0], point.y - perp_vector[1])\n",
    "                ])\n",
    "                \n",
    "                # Append the perpendicular line to the list\n",
    "                perpendiculars.append({'geometry': perp_line})\n",
    "    \n",
    "    # Convert list to GeoDataFrame\n",
    "    perpendiculars_gdf = gpd.GeoDataFrame(perpendiculars, crs=gdf.crs)\n",
    "    \n",
    "    # Save the perpendicular lines to the same geopackage\n",
    "    out_gpkg_path = gpkg_path.replace('.gpkg', '_perpendiculars_100m.gpkg')\n",
    "    perpendiculars_gdf.to_file(out_gpkg_path, driver='GPKG')\n",
    "\n",
    "def segment_stream_polygon(stream_polygon_path, centerline_path, output_path, n_segments = 200, window=20):\n",
    "    # Load the shapefile and the centerline\n",
    "    gdf = gpd.read_file(stream_polygon_path)\n",
    "    centerline_gdf = gpd.read_file(centerline_path)\n",
    "    \n",
    "    # Assuming the polygon to segment is the first feature in the shapefile\n",
    "    polygon = gdf.geometry[0]\n",
    "    centerline = centerline_gdf.geometry[0]\n",
    "    \n",
    "    # Calculate interval along the centerline to place cutting points\n",
    "    line_length = centerline.length\n",
    "    interval = line_length / n_segments\n",
    "    \n",
    "    # Initialize list to store cutting lines\n",
    "    cutting_lines = []\n",
    "    \n",
    "    for i in range(1, n_segments):\n",
    "        # Calculate the primary interpolation point\n",
    "        point = centerline.interpolate(i * interval)\n",
    "\n",
    "        # Calculate points 20 meters behind and ahead for rolling average\n",
    "        point_back = centerline.interpolate(max(0, i * interval - window))\n",
    "        point_forward = centerline.interpolate(min(line_length, i * interval + window))\n",
    "        \n",
    "        # Determine vectors to these points\n",
    "        dx_back, dy_back = point.x - point_back.x, point.y - point_back.y\n",
    "        dx_forward, dy_forward = point_forward.x - point.x, point_forward.y - point.y\n",
    "        \n",
    "        # Average the vectors\n",
    "        dx_avg = (dx_back + dx_forward) / 2\n",
    "        dy_avg = (dy_back + dy_forward) / 2\n",
    "        \n",
    "        # Compute the perpendicular vector\n",
    "        length_vector = np.sqrt(dx_avg**2 + dy_avg**2)\n",
    "        perp_dx = -dy_avg / length_vector\n",
    "        perp_dy = dx_avg / length_vector\n",
    "        \n",
    "        # Define a long perpendicular line for cutting\n",
    "        start_point = Point(point.x + perp_dx * 1000, point.y + perp_dy * 1000)\n",
    "        end_point = Point(point.x - perp_dx * 1000, point.y - perp_dy * 1000)\n",
    "        cutting_lines.append(LineString([start_point, end_point]))\n",
    "    \n",
    "    # Initial set of segments\n",
    "    segments = [polygon]\n",
    "\n",
    "    # Split the polygon with each line\n",
    "    for line in cutting_lines:\n",
    "        new_segments = []\n",
    "        for segment in segments:\n",
    "            split_result = split(segment, line)\n",
    "            new_segments.extend(split_result.geoms)\n",
    "        segments = new_segments\n",
    "\n",
    "    # Convert segments to GeoDataFrame\n",
    "    segment_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries(segments))\n",
    "\n",
    "    # Set the same CRS as the original\n",
    "    segment_gdf.crs = gdf.crs\n",
    "\n",
    "    # Save to a new shapefile\n",
    "    segment_gdf.to_file(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import centerline\n",
    "import geopandas as gpd\n",
    "from centerline.geometry import Centerline\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def create_centerline(input_geopackage, output_geopackage):\n",
    "    # Read the polygon from the input geopackage\n",
    "    polygon_gdf = gpd.read_file(input_geopackage)\n",
    "    \n",
    "    # Convert to shapely Polygon\n",
    "    polygon = Polygon(polygon_gdf['geometry'][0])\n",
    "    # Calculate the centerline\n",
    "    attributes = {\"valid\": True}\n",
    "\n",
    "    centerline = Centerline(polygon, interpolation_distance = 2, **attributes)\n",
    "    centerline_geoms = []\n",
    "    for geom in centerline.geometry.geoms:\n",
    "        centerline_geoms.append(geom)\n",
    "    \n",
    "    # Create a GeoDataFrame from the centerline\n",
    "    centerline_gdf = gpd.GeoDataFrame(geometry=centerline_geoms)\n",
    "    \n",
    "    # Set the CRS\n",
    "    centerline_gdf.crs = polygon_gdf.crs\n",
    "    \n",
    "    # Save to a new geopackage\n",
    "    centerline_gdf.to_file(output_geopackage, driver='GPKG')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def rank_elevation_mean(input_geopackage, output_geopackage):\n",
    "    \"\"\"\n",
    "    Reads a GeoPackage, ranks features based on the 'Elevation Mean' field,\n",
    "    adds these ranks as a new field 'id', and writes the result to a new GeoPackage.\n",
    "\n",
    "    Parameters:\n",
    "    input_geopackage (str): Path to the input GeoPackage.\n",
    "    output_geopackage (str): Path to the output GeoPackage where the result will be saved.\n",
    "    \"\"\"\n",
    "    # Load the geopackage into a GeoDataFrame\n",
    "    gdf = gpd.read_file(input_geopackage)\n",
    "\n",
    "    # Check if 'Elevation Mean' column exists\n",
    "    if 'Elevation Mean' not in gdf.columns:\n",
    "        raise ValueError(\"The column 'Elevation Mean' does not exist in the provided GeoPackage.\")\n",
    "\n",
    "    # Rank the 'Elevation Mean' values from smallest to largest\n",
    "    # Method should be one of 'average', 'min', 'max', 'first', 'dense'\n",
    "    gdf['fid'] = gdf['Elevation Mean'].rank(method='first').astype(int)\n",
    "\n",
    "    # Write the modified GeoDataFrame to a new geopackage\n",
    "    gdf.to_file(output_geopackage, driver='GPKG')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progeess: 239/240\r"
     ]
    }
   ],
   "source": [
    "from compute_hillslope_attributes import aggregate_raster_stats\n",
    "import os\n",
    "\n",
    "channel_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Channel Polygons JTM\"\n",
    "centerline_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Centerlines\"\n",
    "output_single_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\One Part Polygons\"\n",
    "output_segment_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Segmented Polygons\"\n",
    "output_rough_CL_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Centerlines\\Rough Centerlines\"\n",
    "\n",
    "#channel_poly_paths = [os.path.join(channel_poly_dir, f) for f in os.listdir(channel_poly_dir) if f.endswith('.gpkg')]\n",
    "#centerline_paths = [os.path.join(centerline_dir, f) for f in os.listdir(centerline_dir) if f.endswith('.gpkg')]\n",
    "\n",
    "channel_poly_paths = [\n",
    "    r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\One Part Polygons\\UM1_channel_single_poly.gpkg\",\n",
    " r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\One Part Polygons\\UM2_channel_single_poly.gpkg\"\n",
    "]\n",
    "\n",
    "centerline_paths = [\n",
    "    r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Centerlines\\Manual Centerlines\\UM1 Manual Centerline.gpkg\",\n",
    "    r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Centerlines\\Manual Centerlines\\UM2 Manual Centerline.gpkg\"\n",
    "]\n",
    "\n",
    "if not os.path.exists(output_single_poly_dir):\n",
    "    os.makedirs(output_single_poly_dir)\n",
    "if not os.path.exists(output_segment_poly_dir):\n",
    "    os.makedirs(output_segment_poly_dir)\n",
    "if not os.path.exists(output_rough_CL_dir):\n",
    "    os.makedirs(output_rough_CL_dir)\n",
    "\n",
    "DEM_path = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Terrain Feature Rasters\\Slope.tif\"\n",
    "#\n",
    "segmented_poly_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\Watershed Statistical Analysis\\Watershed Stats\\Channels\\Segmented Polygons\"\n",
    "segmented_poly_paths = [os.path.join(segmented_poly_dir, f) for f in os.listdir(segmented_poly_dir) if f.endswith('.gpkg')]\n",
    "\n",
    "# for channel_path, centerline_path in zip(channel_poly_paths, centerline_paths):\n",
    "#     single_poly_name = os.path.basename(channel_path)[0:3] + \"_channel_single_poly.gpkg\"\n",
    "#     output_single_poly_path = os.path.join(output_single_poly_dir, single_poly_name)\n",
    "#     output_segment_name = os.path.basename(channel_path)[0:3] + \"_channel_segmented.gpkg\"\n",
    "#     output_segment_poly_path = os.path.join(output_segment_poly_dir, output_segment_name)\n",
    "#     output_CL_file = os.path.join(output_rough_CL_dir, \"Rough \" + os.path.basename(centerline_path))\n",
    "    \n",
    "    #multipolygon_to_polygon(channel_path, output_single_poly_path)\n",
    "    #create_centerline(output_single_poly_path, output_CL_file, tolerance=300)\n",
    "\n",
    "    #segment_stream_polygon(output_single_poly_path, centerline_path, output_segment_poly_path)\n",
    "for output_segment_poly_path in segmented_poly_paths:\n",
    "    stats_fields = { 'mean': 'Slope Mean'}\n",
    "    gdf = gpd.read_file(output_segment_poly_path)\n",
    "    aggregate_raster_stats(DEM_path, gdf, output_shapefile_path=output_segment_poly_path, **stats_fields)\n",
    "    #rank_elevation_mean(output_segment_poly_path, output_segment_poly_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
